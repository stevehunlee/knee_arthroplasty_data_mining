---
title: "Data Mining Project"
author: "Jonathan Kuek, jjk2214 & Steve Hun Lee, hl2879"
date: "1 December 2015"
output: html_document
---

###Objective of this analysis
We would like to predict the prices of one medical procedure for Medicare holders in one state of the USA (New York).

###Rationale
We are interested in why does different states in the USA have different prices for the same medical procedure. This project can serve as a preliminary analysis for one state and we can extend this to different states in a future study.

###Background of Medicare
Medicare is a US National Social Insurance that covers people who are 65 years old and older who have worked and paid into the Medicare system. It also includes coverage for younger folks with specific disabilities, end stage renal dieseases and ALS.

Medicare has two main coverage areas: Part A which covers Hospital care and Part B that covers Medical Care. Hospital care includes things like hospitalization costs and In patient care. Medical Care includes medically necessary services and preventive services.

###Our area of focus
We are interested in prices under Medicare Part B Medical Care. Based on the current system, patients would have to bear the cost of the annual deductable and 20% of the co-insurance cost for the treatment. What we predict will be the 80% covered under Medicare, which we can use to obtain a fair estimate by adding back 20% and the annual deductable.

###Predictors
The predictors that we will be using to run our regression are the following:
1. NPPES_PROVIDER_GENDER
2. HCPCS_DRUG_INDICATOR
3. PROVIDER_TYPE 
4. NPPES_PROVIDER_STATE

These are the variables we have identified to be the best predictors for the Medicare amount. 

###Variable of interest
1. average_Medicare_payment_amt

```{r}
# Bringing in the dataset and then simple sorting to identify one medical procedure
library(data.table)
set.seed(111)

med_provide_2013 <- fread("medicare.txt", verbose = T)

data1 <- med_provide_2013[MEDICARE_PARTICIPATION_INDICATOR == "Y"] # We only want to examine providors who participate in medicare

HCPCS_27447 <- data1[HCPCS_CODE == 27447] # total knee arthroplasty
str(HCPCS_27447)

#Separate data by zip code aggregated by the first three digits, may also be interesting to see if there are differences when using smaller regions

knee_data_table <- as.data.table(HCPCS_27447)
knee_data_table[, , by = substr(NPPES_PROVIDER_ZIP, 1, 3)]

HCPCS_27447$NPPES_PROVIDER_ZIP_3_DIG <- substr(HCPCS_27447$NPPES_PROVIDER_ZIP, 
                                               1, 3)

HCPCS_27447$NPPES_PROVIDER_GENDER <- 
  as.factor(HCPCS_27447$NPPES_PROVIDER_GENDER)
HCPCS_27447$PLACE_OF_SERVICE <- as.factor(HCPCS_27447$PLACE_OF_SERVICE)
HCPCS_27447$PROVIDER_TYPE <- as.factor(HCPCS_27447$PROVIDER_TYPE)
HCPCS_27447$NPPES_PROVIDER_STATE <- as.factor(HCPCS_27447$NPPES_PROVIDER_STATE)

#Data of columns with each potential predictor
#Predictors: Gender, State, Provider Type, Place of Service, Drug Indicator, Line Service Count Benefactor Unique Count, Benefactor Day Service Count, Provider Zip 3 digits

potential_data <- subset(HCPCS_27447, 
                         select = (c(6, 12, 14, 16, 20:22, 27, 29)))

#Find best predictors
potential_ols <- lm(AVERAGE_MEDICARE_PAYMENT_AMT ~ ., data = potential_data)

ols_step <- step(potential_ols, trace = F)
#Predictors giving best model: State, Provider Type, Place of Serice, Line Count, Benefactor Count, Benefactor Day Service Count
#We will run all models using these variables and compare them to the ones we chose previously from chosing which predictors were most likely to have an affect on the Medicare amount from understanding the background information

#Get rid of columns of data that we're not using or we won't use ever
essential_data <- subset(HCPCS_27447, select = (c(6:7, 12, 14, 16, 27:29)))
best_data_step <- subset(potential_data, select = (c(2:8)))

provider_type <- unique(essential_data$PROVIDER_TYPE)

sample <- sample(
    nrow(essential_data[essential_data$PROVIDER_TYPE 
                                      == provider_type[1]]),
    floor(nrow(essential_data[essential_data$PROVIDER_TYPE 
                                      == provider_type[1]]) * 0.8),
    replace = F)

training <- essential_data[essential_data$PROVIDER_TYPE 
                                      == provider_type[1]][sample,]
testing <- essential_data[essential_data$PROVIDER_TYPE 
                                      == provider_type[1]][-sample,]

for(i in 2:28){
  
  sample <- sample(
    nrow(essential_data[essential_data$PROVIDER_TYPE 
                                      == provider_type[i]]),
    floor(nrow(essential_data[essential_data$PROVIDER_TYPE 
                                      == provider_type[i]]) * 0.8),
    replace = F)
 
  training <- rbind(training, essential_data[essential_data$PROVIDER_TYPE 
                                      == provider_type[i]][sample,])
  
  testing <- rbind(testing, essential_data[essential_data$PROVIDER_TYPE 
                                      == provider_type[i]][-sample,])
}


provider_type_2 <- unique(best_data_step$PROVIDER_TYPE)

sample_2 <- sample(
    nrow(best_data_step[best_data_step$PROVIDER_TYPE 
                                      == provider_type_2[1]]),
    floor(nrow(best_data_step[best_data_step$PROVIDER_TYPE 
                                      == provider_type_2[1]]) * 0.8),
    replace = F)

training_2 <- best_data_step[best_data_step$PROVIDER_TYPE 
                                      == provider_type_2[1]][sample_2,]
testing_2 <- best_data_step[best_data_step$PROVIDER_TYPE 
                                      == provider_type_2[1]][-sample_2,]

for(i in 2:28){
  
  sample_2 <- sample(
    nrow(best_data_step[best_data_step$PROVIDER_TYPE 
                                      == provider_type_2[i]]),
    floor(nrow(best_data_step[best_data_step$PROVIDER_TYPE 
                                      == provider_type_2[i]]) * 0.8),
    replace = F)
 
  training_2 <- rbind(training_2, best_data_step[best_data_step$PROVIDER_TYPE 
                                      == provider_type_2[i]][sample_2,])
  
  testing_2 <- rbind(testing_2, best_data_step[best_data_step$PROVIDER_TYPE 
                                      == provider_type_2[i]][-sample_2,])
}

```

```{r, echo=FALSE}
#Additional variables for future extension of project
#HCPCS_73560 <- data1[HCPCS_CODE == 73560] # knee x-ray
#HCPCS_73562 <- data1[HCPCS_CODE == 73562] # x-ray
#str(HCPCS_73560)
#str(HCPCS_73562)
```

###Methods applied
1. OLS
```{r}

ols_chosen_predictors <- lm(AVERAGE_MEDICARE_PAYMENT_AMT ~ 
                              NPPES_PROVIDER_GENDER + PLACE_OF_SERVICE + 
                              PROVIDER_TYPE + NPPES_PROVIDER_STATE, 
                            data = training)

ols_best <- lm(AVERAGE_MEDICARE_PAYMENT_AMT ~ ., data = training_2)
summary(ols_chosen_predictors)
summary(ols_best)

predict_ols <- predict(ols_chosen_predictors, newdata = testing)
predict_ols_best <- predict(ols_best, newdata = testing_2)

mse <- function(test, predict){
  
  mean((test - predict)^2)
  
}

mse_ols <- mse(testing$AVERAGE_MEDICARE_PAYMENT_AMT, predict_ols)
mse_ols

mse_best <- mse(testing$AVERAGE_MEDICARE_PAYMENT_AMT, predict_ols_best)
mse_best
```

We see here that our previously chosen variables perform better than the supposed 'best' variables from minimizing the AIC with step.

2. Kernel Smoothing
```{r}
library(ISLR)
library(gam)

step_ols <- step(ols_chosen_predictors)
summary(step_ols)
```
After performing the step function, we can see the it dropped the NPPES_PROVIDER_GENDER function from the OLS regression, leaving us with only three predictors, Place of service, Provider type and Provider State.  

```{r}
training_ordered <- training[order(training$AVERAGE_MEDICARE_PAYMENT_AMT), ]
gam_splined <- gam(AVERAGE_MEDICARE_PAYMENT_AMT ~ (PLACE_OF_SERVICE) + 
                     PROVIDER_TYPE + NPPES_PROVIDER_STATE, 
                   data = training_ordered)

predict_gam <- predict(gam_splined, newdata = testing)
mse_gam <- mse(testing$AVERAGE_MEDICARE_PAYMENT_AMT, predict_gam)
mse_gam
```


3. Tree Based Methods

```{r}
stopifnot(require(randomForest))
stopifnot(require(rpart))
stopifnot(require(bartMachine))

#Random Forest
rf <- randomForest(AVERAGE_MEDICARE_PAYMENT_AMT ~ NPPES_PROVIDER_GENDER + 
                     PLACE_OF_SERVICE + PROVIDER_TYPE + NPPES_PROVIDER_STATE, 
                   data = training)
predict_rf <- predict(rf, newdata = testing)

mse_rf <- mse(testing$AVERAGE_MEDICARE_PAYMENT_AMT, predict_rf)
mse_rf

#rpart
rpart <- rpart(AVERAGE_MEDICARE_PAYMENT_AMT ~ NPPES_PROVIDER_GENDER + 
                     PLACE_OF_SERVICE + PROVIDER_TYPE + NPPES_PROVIDER_STATE, 
               data = training)
predict_rpart <- predict(rpart, newdata = testing)

mse_rpart <- mse(testing$AVERAGE_MEDICARE_PAYMENT_AMT, predict_rpart)
mse_rpart

#bartMachine
bart_model <- bartMachine(X = as.data.frame(subset(training, 
                                                   select =c(1,3:5))), 
                          y = training$AVERAGE_MEDICARE_PAYMENT_AMT)
bart_predict <- predict(bart_model, new_data = as.data.frame(subset(testing, 
                                                   select =c(1,3:5))))

mse_bart <- mse(testing$AVERAGE_MEDICARE_PAYMENT_AMT, bart_predict)
mse_bart
```

4. Neural Networks

```{r}
library(RSNNS)
train_target <- training$AVERAGE_MEDICARE_PAYMENT_AMT
train_inputs <- model.matrix(~ NPPES_PROVIDER_GENDER + PLACE_OF_SERVICE + PROVIDER_TYPE + NPPES_PROVIDER_STATE - 1, data = training)

test_target <- testing$AVERAGE_MEDICARE_PAYMENT_AMT
test_inputs <- model.matrix(~ NPPES_PROVIDER_GENDER + PLACE_OF_SERVICE + PROVIDER_TYPE + NPPES_PROVIDER_STATE - 1, data = testing)

train_inputs <- normalizeData(train_inputs)
test_inputs <- normalizeData(test_inputs)

NN_1 <- elman(x = train_inputs, y = train_target, size = 1,
              learnFuncParams = c(0.1), maxit = 500,
              inputsTest = test_inputs, targetsTest = test_target,
              linOut = TRUE)
predict_NN_1 <- predict(NN_1, newdata = test_inputs)
mse_NN_1 <- mse(testing$AVERAGE_MEDICARE_PAYMENT_AMT, predict_NN_1)
mse_NN_1

NN_2 <- elman(x = train_inputs, y = train_target, size = 2,
              learnFuncParams = c(0.1), maxit = 500,
              inputsTest = test_inputs, targetsTest = test_target,
              linOut = TRUE)
predict_NN_2 <- predict(NN_2, newdata = test_inputs)
mse_NN_2 <- mse(testing$AVERAGE_MEDICARE_PAYMENT_AMT, predict_NN_2)
mse_NN_2

NN_3 <- elman(x = train_inputs, y = train_target, size = 3,
              learnFuncParams = c(0.1), maxit = 500,
              inputsTest = test_inputs, targetsTest = test_target,
              linOut = TRUE)
predict_NN_3 <- predict(NN_3, newdata = test_inputs)
mse_NN_3 <- mse(testing$AVERAGE_MEDICARE_PAYMENT_AMT, predict_NN_3)
mse_NN_3

NN_4 <- elman(x = train_inputs, y = train_target, size = 4, 
              learnFuncParams = c(0.1), maxit = 500,
              inputsTest = test_inputs, targetsTest = test_target,
              linOut = TRUE)
predict_NN_4 <- predict(NN_4, newdata = test_inputs)
mse_NN_4 <- mse(testing$AVERAGE_MEDICARE_PAYMENT_AMT, predict_NN_4)
mse_NN_4

NN_5 <- elman(x = train_inputs, y = train_target, size = 5,
              learnFuncParams = c(0.1), maxit = 500,
              inputsTest = test_inputs, targetsTest = test_target,
              linOut = TRUE)
predict_NN_5 <- predict(NN_5, newdata = test_inputs)
mse_NN_5 <- mse(testing$AVERAGE_MEDICARE_PAYMENT_AMT, predict_NN_5)
mse_NN_5
```

5. Additional Methods - Extreme Gradient Boosting

```{r}
stopifnot(require(xgboost))
#Extreme Gradient Boosting

training$NPPES_PROVIDER_GENDER <- as.numeric(training$NPPES_PROVIDER_GENDER)
training$PLACE_OF_SERVICE <- as.numeric(training$PLACE_OF_SERVICE)
training$PROVIDER_TYPE <- as.numeric(training$PROVIDER_TYPE)
training$NPPES_PROVIDER_STATE <- as.numeric(training$NPPES_PROVIDER_STATE)

testing$NPPES_PROVIDER_GENDER <- as.numeric(testing$NPPES_PROVIDER_GENDER)
testing$PLACE_OF_SERVICE <- as.numeric(testing$PLACE_OF_SERVICE)
testing$PROVIDER_TYPE <- as.numeric(testing$PROVIDER_TYPE)
testing$NPPES_PROVIDER_STATE <- as.numeric(testing$NPPES_PROVIDER_STATE)


xgboost <- xgboost(data = data.matrix(subset(training, 
                                             select = c(1,3:5))),
                   label = training$AVERAGE_MEDICARE_PAYMENT_AMT,
                   nrounds = 100,
                   objective = "reg:linear",
               eval_metric = "rmse")
testing_data <- subset(testing, select = c(1,3:5))
predict_xgboost <- predict(xgboost, data.matrix(testing_data))

mse_xgboost <- mse(testing$AVERAGE_MEDICARE_PAYMENT_AMT, predict_xgboost)

mse_optimization <- c()
for(i in seq(1,1000, by = 50)){
xgboost_test <- xgboost(data = data.matrix(subset(training, 
                                             select = c(1,3:5))),
                   label = training$AVERAGE_MEDICARE_PAYMENT_AMT,
                   nrounds = i,
                   objective = "reg:linear",
               eval_metric = "rmse")
testing_data_test <- subset(testing, select = c(1,3:5))
predict_xgboost_test <- predict(xgboost_test, data.matrix(testing_data_test))

mse_optimization[i] <- mse(testing$AVERAGE_MEDICARE_PAYMENT_AMT, 
                           predict_xgboost_test)
}
which.min(mse_optimization)

#model using 51 rounds is optimal xgboost model

best_xgboost <- xgboost(data = data.matrix(subset(training, 
                                             select = c(1,3:5))),
                   label = training$AVERAGE_MEDICARE_PAYMENT_AMT,
                   nrounds = 51,
                   objective = "reg:linear",
               eval_metric = "rmse")
testing_data_best <- subset(testing, select = c(1,3:5))
predict_xgboost_best <- predict(best_xgboost, data.matrix(testing_data_best))

mse_xgboost_best <- mse(testing$AVERAGE_MEDICARE_PAYMENT_AMT, 
                        predict_xgboost_best)
mse_xgboost_best
```

Table of MSE

```{r}
mse_names <- c("Best Ols", "OLS", "GAM", "NN_1", "NN_2", "NN_3", "NN_4", "NN_5", "Random Forest", "Rpart", "Xgboost", "Xgboost Best")


all_mse <- c(mse_best, mse_ols, mse_gam, mse_NN_1, mse_NN_2, mse_NN_3, mse_NN_4, mse_NN_5, mse_rf, mse_rpart, mse_xgboost, mse_xgboost_best)

mse_table <- cbind(mse_names, all_mse, row.names = mse_names)

which.min(mse_table[,2])
mse_table[12,3]

```

###Conclusion
The method that predicts the best amongst those that we tried is xgboost with 51 iterations.
